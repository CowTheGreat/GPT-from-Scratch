{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3d6ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "file_path = \"LLM-2hrs-shakespear/input.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66256e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81939ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 1115394\n",
      "Tokens: 338025\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fdf17895",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.95\n",
    "split_idx = int(len(text_data) * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e4e7bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18c85466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d96550f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "625\n",
      "\n",
      "Validation loader:\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "print(len(train_loader))\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64edcd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 320000\n",
      "Validation tokens: 17920\n",
      "All tokens: 337920\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a737716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "191480da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    \n",
    "    logits = model(input_batch)\n",
    "    logits_flat = logits.flatten(0, 1)\n",
    "    targets_flat = target_batch.flatten()\n",
    "    \n",
    "    loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eeffba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "182c759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "            # Print a sample text after each epoch\n",
    "                generate_and_print_sample(\n",
    "                    model, tokenizer, device, start_context\n",
    "                )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80a164bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "771c429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.454, Val loss 9.376\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000025): Train loss 6.586, Val loss 6.674\n",
      "First Citizen:                           I: I:       I:   I:    \n",
      "Ep 1 (Step 000050): Train loss 6.229, Val loss 6.288\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000075): Train loss 6.059, Val loss 6.210\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000100): Train loss 6.029, Val loss 6.107\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000125): Train loss 5.935, Val loss 6.042\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000150): Train loss 5.608, Val loss 5.943\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000175): Train loss 5.711, Val loss 5.856\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000200): Train loss 5.601, Val loss 5.774\n",
      "First Citizen:  IUS:        IUS:      IUS:                 IUS:     \n",
      "Ep 1 (Step 000225): Train loss 5.435, Val loss 5.714\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000250): Train loss 5.438, Val loss 5.594\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000275): Train loss 5.484, Val loss 5.557\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000300): Train loss 5.333, Val loss 5.538\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000325): Train loss 5.153, Val loss 5.486\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000350): Train loss 5.261, Val loss 5.485\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000375): Train loss 5.069, Val loss 5.452\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000400): Train loss 5.181, Val loss 5.403\n",
      "First Citizen: And, And I will be a thousand, And, And I have a thousand, And I have a thousand, And, And I will be a thousand, And I have a thousand, And, \n",
      "Ep 1 (Step 000425): Train loss 5.104, Val loss 5.400\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000450): Train loss 4.942, Val loss 5.330\n",
      "First Citizen:  I'll not,                                            \n",
      "Ep 1 (Step 000475): Train loss 5.030, Val loss 5.357\n",
      "First Citizen:  And, And I have a king,                                       \n",
      "Ep 1 (Step 000500): Train loss 4.787, Val loss 5.323\n",
      "First Citizen: And not, And, And, And I have I have not, And I have I have a devil, And I have not, And not be a devil, And I have not, And I have\n",
      "Ep 1 (Step 000525): Train loss 4.974, Val loss 5.267\n",
      "First Citizen:                                                  \n",
      "Ep 1 (Step 000550): Train loss 4.832, Val loss 5.230\n",
      "First Citizen: And I have I have I have I have a man, And I have a man, And I have a man, And I have a man, And I have I have a man, And I have a man,\n",
      "Ep 1 (Step 000575): Train loss 4.931, Val loss 5.200\n",
      "First Citizen: And I do you, And I do you,  And I do you, And I do you, And I do you,       And I do you, And I do you, \n",
      "Ep 1 (Step 000600): Train loss 4.917, Val loss 5.231\n",
      "First Citizen: And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And\n",
      "Ep 2 (Step 000625): Train loss 4.923, Val loss 5.228\n",
      "First Citizen:                                                  \n",
      "Ep 2 (Step 000650): Train loss 4.725, Val loss 5.193\n",
      "First Citizen: And, And I will be so, And I will be not, And I will not, And I will be not, And, And I will not, And I will not, And, And\n",
      "Ep 2 (Step 000675): Train loss 4.736, Val loss 5.185\n",
      "First Citizen:  And,   And I will not a man, And,  And I have a man,    And I am a man,       And I have a man,  \n",
      "Ep 2 (Step 000700): Train loss 4.713, Val loss 5.167\n",
      "First Citizen: And I have been, And I have been a word.                                    \n",
      "Ep 2 (Step 000725): Train loss 4.773, Val loss 5.126\n",
      "First Citizen: And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And\n",
      "Ep 2 (Step 000750): Train loss 4.703, Val loss 5.121\n",
      "First Citizen:  I'll be,                                            \n",
      "Ep 2 (Step 000775): Train loss 4.654, Val loss 5.094\n",
      "First Citizen: And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And\n",
      "Ep 2 (Step 000800): Train loss 4.629, Val loss 5.123\n",
      "First Citizen: And you, And you, And you, And you, And you, And you, And you,  And you, And you, And you, And you, And you, \n",
      "Ep 2 (Step 000825): Train loss 4.694, Val loss 5.079\n",
      "First Citizen: And I have been, And I have you, And I have you, And, And, And, And, And, And, And, And, And I have you, And\n",
      "Ep 2 (Step 000850): Train loss 4.569, Val loss 5.100\n",
      "First Citizen: I am not, And I am not, And I am not, And I am not, And I am not, And I am not, And I am not, And I am not, And I\n",
      "Ep 2 (Step 000875): Train loss 4.653, Val loss 5.120\n",
      "First Citizen:                                                  \n",
      "Ep 2 (Step 000900): Train loss 4.485, Val loss 5.131\n",
      "First Citizen:                                                  \n",
      "Ep 2 (Step 000925): Train loss 4.612, Val loss 5.096\n",
      "First Citizen: And I will not And, And I will not And I do not And I do not And, And I do not, And, And I will not And I will not And, And\n",
      "Ep 2 (Step 000950): Train loss 4.598, Val loss 5.075\n",
      "First Citizen: And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And\n",
      "Ep 2 (Step 000975): Train loss 4.501, Val loss 5.052\n",
      "First Citizen: And let us, And let us, And let us, And let us, And let us, And let us, And let us, And let us, And let us, And, And\n",
      "Ep 2 (Step 001000): Train loss 4.706, Val loss 5.012\n",
      "First Citizen: And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And\n",
      "Ep 2 (Step 001025): Train loss 4.453, Val loss 5.024\n",
      "First Citizen: And I'll be a man, And, And, And, And I'll have a man, And, And, And, And, And, And I'll have been, And,\n",
      "Ep 2 (Step 001050): Train loss 4.562, Val loss 4.998\n",
      "First Citizen: And I'll not, And, And, And, And, And, And I am a man, And, And, And, And, And I'll not, And I'll\n",
      "Ep 2 (Step 001075): Train loss 4.573, Val loss 5.052\n",
      "First Citizen: And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And\n",
      "Ep 2 (Step 001100): Train loss 4.401, Val loss 4.999\n",
      "First Citizen: And I'll be And I have a And I have a And, And I have a And I have a And I have a And I have a And, And I have a And I have\n",
      "Ep 2 (Step 001125): Train loss 4.392, Val loss 5.016\n",
      "First Citizen: And I will be so.                                           \n",
      "Ep 2 (Step 001150): Train loss 4.524, Val loss 4.998\n",
      "First Citizen: And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And\n",
      "Ep 2 (Step 001175): Train loss 4.439, Val loss 5.027\n",
      "First Citizen: And I am a man, And, And, And, And, And, And, And, And, And, And, And, And, And, And, \n",
      "Ep 2 (Step 001200): Train loss 4.467, Val loss 5.013\n",
      "First Citizen: And I'll be a man.                                          \n",
      "Ep 2 (Step 001225): Train loss 4.470, Val loss 4.996\n",
      "First Citizen: And, And, And, And, And, And, And, I am not, And, And, And, And, And, And, And, And,\n",
      "Ep 3 (Step 001250): Train loss 4.506, Val loss 5.015\n",
      "First Citizen: I have been a You are a    IUS: IUS: IUS: You are not, You are not,    You are not, You are not, You are\n",
      "Ep 3 (Step 001275): Train loss 4.315, Val loss 4.969\n",
      "First Citizen: I will you, I am a And you, I am a I have a And you, And you, 'Tis a man.        I'll make you, \n",
      "Ep 3 (Step 001300): Train loss 4.363, Val loss 4.984\n",
      "First Citizen: I have you, I have you.       IUS: IUS: IUS: I would you, I have you, I have you, I have you, I have you, I have\n",
      "Ep 3 (Step 001325): Train loss 4.323, Val loss 4.983\n",
      "First Citizen: I'll not be gone.                      Nay,  Nay, I would not,  Nay, I would\n",
      "Ep 3 (Step 001350): Train loss 4.358, Val loss 4.994\n",
      "First Citizen: IUS: I think you, IUS: I think you, I think, IUS: IUS: IUS: IUS: IUS: IUS: IUS:\n",
      "Ep 3 (Step 001375): Train loss 4.299, Val loss 5.011\n",
      "First Citizen: I am a And, I am a And, And, And, And, And, And, And, And, And, And, And, And, And,\n",
      "Ep 3 (Step 001400): Train loss 4.210, Val loss 4.995\n",
      "First Citizen: I'll have been I am I am a a  AUTOLYCUS: I am a  AUTOLYCUS: I am not AUTOLYCUS: I am a  AUTOL\n",
      "Ep 3 (Step 001425): Train loss 4.286, Val loss 4.952\n",
      "First Citizen: I'll tell you, I am a man, I am a And, And, And, And, I am a man of a man, And, And, And, And, \n",
      "Ep 3 (Step 001450): Train loss 4.214, Val loss 4.975\n",
      "First Citizen: I'll have done.  Third Citizen: I'll have done.      Third Citizen: I will be not the I will be I will be not the I will be done.  \n",
      "Ep 3 (Step 001475): Train loss 4.213, Val loss 4.966\n",
      "First Citizen: IUS: IUS: IUS: IUS: I have been, sir, sir, I have been, sir, sir, sir, sir, sir, sir, sir, I have you, sir, sir\n",
      "Ep 3 (Step 001500): Train loss 4.313, Val loss 4.960\n",
      "First Citizen: I'll not, IUS: IOLANUS: IOLYCUS: IUS: IUS: IUS: IUS: IUS: I have not, I have not\n",
      "Ep 3 (Step 001525): Train loss 4.064, Val loss 4.955\n",
      "First Citizen: I'll not, And, And, And, And, And, And, And, And, And, And, And, And, And, And, And,\n",
      "Ep 3 (Step 001550): Train loss 4.110, Val loss 4.917\n",
      "First Citizen: 'Tis a little, And, And I'll be so.  LUCENTIO: 'Tis, And I'll be a And I'll not.  LUCENTIO: I\n",
      "Ep 3 (Step 001575): Train loss 4.224, Val loss 4.976\n",
      "First Citizen: I' the people, And I am a And, And I am a And, And in the And, And I am a And, And, And, And I am a man of\n",
      "Ep 3 (Step 001600): Train loss 4.184, Val loss 4.946\n",
      "First Citizen: I'ld have you, I'ld have you, I'ld have you, And, I'ld have a And, And, And, I'ld have the And, And\n",
      "Ep 3 (Step 001625): Train loss 4.051, Val loss 4.921\n",
      "First Citizen: What shall have been First Servingman: You have you have been a First Servingman: You have you have been a him.  First Servingman: Clown: You have been a First Serving\n",
      "Ep 3 (Step 001650): Train loss 4.048, Val loss 4.903\n",
      "First Citizen: I have you, And so, And so, And so, I have been a man.  Second Citizen: I have been a man, And so, And so, And so, And\n",
      "Ep 3 (Step 001675): Train loss 4.009, Val loss 4.896\n",
      "First Citizen: ' the people, And, And, I'll be so, And, And, And, I'll be so, And, And, And, And, And, And,\n",
      "Ep 3 (Step 001700): Train loss 4.156, Val loss 4.918\n",
      "First Citizen: I have you, sir, sir, And I have been you, And you, And, sir, And, And you, And, And you, sir, And you have been not, And\n",
      "Ep 3 (Step 001725): Train loss 4.009, Val loss 4.919\n",
      "First Citizen:  Second Citizen: I have you have been to be a man, And, To have a man.  Second Citizen: The people, And, And, And I have been, And, \n",
      "Ep 3 (Step 001750): Train loss 3.982, Val loss 4.899\n",
      "First Citizen: Ay, And, sir, sir, sir, sir, And, sir, sir, And, I will have you have been so much.  First Musician: No, I will have you have you, sir\n",
      "Ep 3 (Step 001775): Train loss 4.183, Val loss 4.894\n",
      "First Citizen: I'll tell you have you have you, And, sir, And, sir, sir, And, And, sir, sir, sir, And, sir, And, sir, And, sir, \n",
      "Ep 3 (Step 001800): Train loss 4.010, Val loss 4.866\n",
      "First Citizen: I will be, And, sir, sir, And, sir, sir, sir, And, sir, And, sir: And, sir, sir, sir, sir, sir, sir, sir, sir,\n",
      "Ep 3 (Step 001825): Train loss 4.060, Val loss 4.878\n",
      "First Citizen: I'll not, And, And, I'll not, And, I'll not, And, I'll not, And, And, I'll not, And, I'll have been not, And\n",
      "Ep 3 (Step 001850): Train loss 3.910, Val loss 4.835\n",
      "First Citizen: I'll not, And, And, I'll not the common people, And, I'll make me, And, And, And, I'll not, I'll not the common of the \n",
      "Ep 4 (Step 001875): Train loss 3.962, Val loss 4.838\n",
      "First Citizen: I'll tell him, And what you are you, And what you, And what you are you, And then, And what you are to the king.  Third Servingman: I'll tell him,\n",
      "Ep 4 (Step 001900): Train loss 4.023, Val loss 4.886\n",
      "First Citizen: I will be And I will be And yet you shall be you.  First Citizen: I am I will be gone.  First Citizen: I am a  First Citizen: I am a man of\n",
      "Ep 4 (Step 001925): Train loss 3.773, Val loss 4.926\n",
      "First Citizen: 'Tis, I'll tell thee, And, I am I am a And, I am a To be gone.  First Citizen: I am a  First Citizen: What's a And\n",
      "Ep 4 (Step 001950): Train loss 3.937, Val loss 4.919\n",
      "First Citizen: Why, I am a us, And, I'll have a Christian Second Servingman: I'll have a Second Servingman: I'll have a theown: I'll have a the man's\n",
      "Ep 4 (Step 001975): Train loss 3.992, Val loss 4.943\n",
      "First Citizen: What, And, what, what's dead, And, what's dead, And, And, And, And, And what I will not the people, And, And, And I have\n",
      "Ep 4 (Step 002000): Train loss 4.024, Val loss 4.918\n",
      "First Citizen: I have you, I have you, I have you, I have you, And, And I have you, And I have you, And I have you, I have you, I have you\n",
      "Ep 4 (Step 002025): Train loss 3.950, Val loss 4.941\n",
      "First Citizen:   First Murderer: I will not, And, I will not, And, I will not the king, And, And I will not the king.  CLARENCE: I will not the\n",
      "Ep 4 (Step 002050): Train loss 3.882, Val loss 4.928\n",
      "First Citizen: 'Tis more than a man.  First Gentleman: What is a the the theown: I'll have heard a thee' the the the thee' the thee'\n",
      "Ep 4 (Step 002075): Train loss 3.807, Val loss 4.884\n",
      "First Citizen: I'll tell thee.  Second Servingman: I'll tell me, sir, sir, sir, sir, sir, sir, sir, And I'll have done.  Second Servingman: I'll have you\n",
      "Ep 4 (Step 002100): Train loss 3.796, Val loss 4.941\n",
      "First Citizen: I'll tell you, And, And, And, And, And, And, And, And, And, And, And so you, And, And, And,\n",
      "Ep 4 (Step 002125): Train loss 3.756, Val loss 4.913\n",
      "First Citizen: Why, And, sir, sir, And, sir, And, And, And, sir, And, and you are you are too.  First Citizen: I'll be you are you. \n",
      "Ep 4 (Step 002150): Train loss 3.866, Val loss 4.893\n",
      "First Citizen: I'll be so.  First Citizen: I am a gentleman.  First Citizen: I know you are you.  First Citizen: I am, sir, sir, sir, sir, sir, sir,\n",
      "Ep 4 (Step 002175): Train loss 3.836, Val loss 4.916\n",
      "First Citizen: I'll be satisfied.  First Citizen: I'll tell you.  Third Citizen: I'll tell you, sir, sir, sir.  Third Citizen: I'll tell you, sir, sir. \n",
      "Ep 4 (Step 002200): Train loss 3.771, Val loss 4.921\n",
      "First Citizen: I'll hear me to the people.  MENENIUS: IUS: I am sure.  MENENIUS: IUS: IUS: I'll hear me to the people. \n",
      "Ep 4 (Step 002225): Train loss 3.731, Val loss 4.882\n",
      "First Citizen: I am I'll leave you, And yet I'll not a word.  KING HENRY VI: I am I'll be the king, And yet I'll be the king, And yet I'll be the\n",
      "Ep 4 (Step 002250): Train loss 3.725, Val loss 4.877\n",
      "First Citizen: 'Tis not, And, And now, And, And, And, And, And, And, And, And, And, And, And, And, \n",
      "Ep 4 (Step 002275): Train loss 3.655, Val loss 4.895\n",
      "First Citizen: I'll not, sir, I am a gentleman, I'll not a good I'll not a man, I'll not a good the gentleman, I'll not a man of my life, I'll not\n",
      "Ep 4 (Step 002300): Train loss 3.704, Val loss 4.866\n",
      "First Citizen: IUS: I am a gentleman of the the the general, I have been a the general: I have been a the the the the the the general, I am a \n",
      "Ep 4 (Step 002325): Train loss 3.583, Val loss 4.872\n",
      "First Citizen: I am a man.  CORIOLANUS: IOLANUS: IOLANUS: IOLANUS: IOLANUS: IOLANUS: IOLANUS:\n",
      "Ep 4 (Step 002350): Train loss 3.651, Val loss 4.868\n",
      "First Citizen: I'll tell thee, sir, sir, And, sir, sir, sir, sir, And, sir, And, sir, sir, sir, sir, sir, sir, And you have been a To see\n",
      "Ep 4 (Step 002375): Train loss 3.699, Val loss 4.882\n",
      "First Citizen: I'll tell you, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, And, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir\n",
      "Ep 4 (Step 002400): Train loss 3.707, Val loss 4.876\n",
      "First Citizen: My lord, my lord, And, And, my lord, And, And, my lord, And, my lord, And, my lord, And, And, my lord, And, my\n",
      "Ep 4 (Step 002425): Train loss 3.578, Val loss 4.883\n",
      "First Citizen: I will not be a man.  Third Servingman: I'll tell you, And, sir, And, sir, And, sir, And, sir, And, my lord, And, my\n",
      "Ep 4 (Step 002450): Train loss 3.806, Val loss 4.852\n",
      "First Citizen: My lord, I have done to the king, And, I do repent thee, And, And, I will be so, And, And, I do repent thee, And, I say, And,\n",
      "Ep 4 (Step 002475): Train loss 3.766, Val loss 4.857\n",
      "First Citizen: You are not be the people, sir.  AUTOLYCUS: You are you, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir\n",
      "Ep 5 (Step 002500): Train loss 3.622, Val loss 4.854\n",
      "First Citizen: I have not, thee you have you have you have you, sir, sir, sir, sir, you have you have you, sir, sir, I have you have you, sir, sir, sir, sir\n",
      "Ep 5 (Step 002525): Train loss 3.673, Val loss 4.903\n",
      "First Citizen: Well, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir\n",
      "Ep 5 (Step 002550): Train loss 3.586, Val loss 4.908\n",
      "First Citizen: I'enius, sir.  AUTOLYCUS: I do not a AUTOLYCUS: I have you have been a tapster.  AUTOLYCUS: I know you, sir,\n",
      "Ep 5 (Step 002575): Train loss 3.608, Val loss 4.925\n",
      "First Citizen: Ay, And, I have been so, I have been too much more.  LADY CAPULET: I will I will not be gone.  CAPULET: I'll tell thee, sir,\n",
      "Ep 5 (Step 002600): Train loss 3.661, Val loss 4.956\n",
      "First Citizen: 'Tis a word, I will be a man, And make you have you have been a soldier.  PETRUCHIO: I will be you, sir, sir, sir, sir, sir, sir\n",
      "Ep 5 (Step 002625): Train loss 3.733, Val loss 4.953\n",
      "First Citizen: Ay, sir, sir, sir, sir.  Third Citizen: Ay, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir\n",
      "Ep 5 (Step 002650): Train loss 3.410, Val loss 4.948\n",
      "First Citizen: Why, sir, sir, sir, sir.  Third Citizen: I'll not you, sir.  Third Citizen: Why, sir.  Third Citizen: I'll tell you, sir.  Third\n",
      "Ep 5 (Step 002675): Train loss 3.744, Val loss 4.943\n",
      "First Citizen: Ay, sir, sir.  First Citizen: Ay, sir, sir, sir, sir, sir, sir, sir.  Second Murderer: What, sir, sir, sir, sir, sir, sir,\n",
      "Ep 5 (Step 002700): Train loss 3.499, Val loss 4.950\n",
      "First Citizen: I'll tell you, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir,\n",
      "Ep 5 (Step 002725): Train loss 3.465, Val loss 4.944\n",
      "First Citizen: I am a aant: I have been a To make the king's  First Watchman: I'll tell you shall be To hear the people of the people, And you have been To make him\n",
      "Ep 5 (Step 002750): Train loss 3.351, Val loss 4.932\n",
      "First Citizen: I am a man of the king's a man thee' the king's  Second Servingman: I' the thee'er-p of the in of the mptest.  Third Serving\n",
      "Ep 5 (Step 002775): Train loss 3.403, Val loss 4.949\n",
      "First Citizen: Ay, sir, my lord, my lord, my lord, And I am not so I'll not be a child, And I'll not a child, my lord.  First Servingman: Well, I'll not\n",
      "Ep 5 (Step 002800): Train loss 3.491, Val loss 4.954\n",
      "First Citizen: 'Tis a man.  Second Servingman: I'Tis, then, I'll be a great a greatable, And yet you have you have been so, And yet you have you to be\n",
      "Ep 5 (Step 002825): Train loss 3.483, Val loss 4.916\n",
      "First Citizen: I am a man, And then, I am a man, To the king's I am a man, I am a man, And then, I am a man, And yet I am a man.\n",
      "Ep 5 (Step 002850): Train loss 3.618, Val loss 4.929\n",
      "First Citizen: Why, I am a man of the king, And that the king's the king of the king, And then the king'st thou hast done, And yet thou hast said to the king'st thou hast done a man\n",
      "Ep 5 (Step 002875): Train loss 3.418, Val loss 4.917\n",
      "First Citizen: I am sure, I'll be so.  Second Servingman: I am a him.  Third Servingman: I am a Roman, sir, sir, sir, sir, sir, sir, sir,\n",
      "Ep 5 (Step 002900): Train loss 3.480, Val loss 4.936\n",
      "First Citizen: 'Twas, I am a Roman, I am a Roman, And then I am a Roman, And then I am a Roman, And then I am a Roman, And I am a Roman, And\n",
      "Ep 5 (Step 002925): Train loss 3.360, Val loss 4.922\n",
      "First Citizen: 'Tis done the king, I'll prove you, And I am not the king.  First Citizen: I'll prove you well: 'Tis not the king.  First Citizen: I'll be\n",
      "Ep 5 (Step 002950): Train loss 3.535, Val loss 4.889\n",
      "First Citizen: I'll be so.  First Musician: I'll be so.  Second Musician: I'll be so.  Second Musician: I would I am Second Musician: I would have\n",
      "Ep 5 (Step 002975): Train loss 3.427, Val loss 4.905\n",
      "First Citizen: I amends you, sir, sir, sir, I am I am not have not to be a have you, sir, have you have you have you to the house.  CORIOLANUS\n",
      "Ep 5 (Step 003000): Train loss 3.414, Val loss 4.926\n",
      "First Citizen: I'll tell you.  First Citizen: I am a him, you are, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, sir, And you, sir\n",
      "Ep 5 (Step 003025): Train loss 3.326, Val loss 4.890\n",
      "First Citizen: I'll not be so.  First Citizen: I'll not be so: I'll be so.  Second Citizen: I'll not be so: I'll not so: I'll not be so.\n",
      "Ep 5 (Step 003050): Train loss 3.250, Val loss 4.883\n",
      "First Citizen: What is the the duke?  Third Citizen: What's the Third Citizen: What's the and, sir?  Third Citizen: I would not the Third Citizen: What, sir,\n",
      "Ep 5 (Step 003075): Train loss 3.471, Val loss 4.893\n",
      "First Citizen: I'Tis not a MOPSA: I have a and a fend me, And you are you, And you are not a the great Marry, sir, And you are you\n",
      "Ep 5 (Step 003100): Train loss 3.387, Val loss 4.879\n",
      "First Citizen: You are not.  First Servingman: I am a man.  Third Servingman: I am a man, sir, sir, sir, sir, And you not.  Third Servingman: I\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=25, eval_iter=25,\n",
    "    start_context=\"First Citizen:\", tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad7e5b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0bd14113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " First Citizen: Before we proceed any further, hear me speak.\n",
      "The great\n",
      "Claudio? What\n",
      "Clown:\n",
      "\n",
      "First Lord:\n",
      "NORIZs must come, that, so, and your\n",
      "h you to you\n",
      "our. Farewell. There is that thou not speak a great\n",
      "your princely\n",
      "will your charge; you are they come; for, he hath all so well: they\n",
      "would be so. What hath no honest.\n",
      "\n",
      "AUTOLYCUS:\n",
      "The general of a very hot, sir;\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"First Citizen: Before we proceed any further, hear me speak.\", tokenizer),\n",
    "    max_new_tokens=100,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "17eacd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"Models/shakespear_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "656ae8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"Models/shakespear_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
